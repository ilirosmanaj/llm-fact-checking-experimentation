from utils.utils import *
from pipeline import *


class Reprompter(PipelineLLM, PipelinePrompt):
    """
    Reprompter class for handling the re-prompting process in a pipeline.
    This model is called when the hallucination threshold is exceeded.


    Methods:
        __init__(config: dict):
            Initializes the Reprompter with the given configuration.

        get_model_prompt(question, generated_answer, reference_documents, answer_triplets, prediction_binary, **kwargs)
            Generates a model prompt based on the provided inputs.

        reprompt_input_formatter(question, generated_answer, reference_documents, answer_triplets, prediction_binary)
            Formats the input for the re-prompting process.

        input_output_format:
            Property that defines the input and output format for the re-prompting process.

            Returns:
                dict: A dictionary containing the input and output format.
    """

    def __init__(self, config: dict, logger: logging.Logger):
        self.logger = logger
        PipelineLLM.__init__(self, config)
        PipelinePrompt.__init__(self, config)

    def get_model_prompt(
        self,
        question: str,
        generated_answer: str,
        reference_documents: list,
        answer_triplets: list,
        prediction_binary: dict,
        **kwargs
    ):
        """
        Generates a model prompt based on the provided inputs.
            question (str): The original question.
            generated_answer (str): The answer generated by the model.
            reference_documents (list): A list of reference documents.
            answer_triplets (list): A list of answer triplets.
            prediction_binary (dict): A dictionary indicating which triplets are hallucinated.

        Returns:
            dict: A dictionary containing the formatted re-prompt input."""
        return self.message_list_template["reprompt"].invoke(
            input=self.reprompt_input_formatter(
                question=question,
                generated_answer=generated_answer,
                reference_documents=reference_documents,
                answer_triplets=answer_triplets,
                prediction_binary=prediction_binary,
            )
        )

    def reprompt_input_formatter(
        self,
        question: str,
        generated_answer: str,
        reference_documents: list,
        answer_triplets: list,
        prediction_binary: dict,
    ):
        """
        Formats the input for the re-prompting process.
            question (str): The original question.
            generated_answer (str): The answer generated by the model.
            reference_documents (list): A list of reference documents.
            answer_triplets (list): A list of answer triplets.
            prediction_binary (dict): A dictionary indicating which triplets are hallucinated.

        Returns:
            dict: A dictionary containing the formatted re-prompt input.
        """
        return {
            "question": question,
            "generated_answer": generated_answer,
            "reference_documents": "\n- ".join(reference_documents),
            "hallucinated_triplets": "\n- ".join(
                [
                    " ".join(answer_triplets[idx])
                    for idx, pred_result in prediction_binary.items()
                    if pred_result == False
                ]
            ),
        }

    @property
    def input_output_format(self):
        return {
            "input": [
                "reference_documents",
                "question",
                "generated_answer",
                "answer_triplets",
                "fact_check_prediction_binary",
            ],
            "output": ["generated_answer"],
        }
